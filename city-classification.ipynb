{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90279,"databundleVersionId":10477255,"sourceType":"competition"}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras.regularizers import l2\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import (Conv2D, BatchNormalization, Activation, \n                                     MaxPooling2D, Dropout, Flatten, Dense)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd \nimport os\n\n\ncsv_path = \"/kaggle/input/datathon-ai-qualification-round/train_data.csv\"\n\n\nlabels_df = pd.read_csv(csv_path)\n\n\ntrain_dir = \"/kaggle/input/datathon-ai-qualification-round/train/train\"\ntest_dir = \"/kaggle/input/datathon-ai-qualification-round/test/test\"\nlabels_df['path'] = labels_df['filename'].apply(lambda x: os.path.join(train_dir, x))\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2  \n)\n\n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=labels_df,\n    directory=train_dir,\n    x_col=\"filename\",\n    y_col=\"city\",  \n    target_size=(64, 64),\n    batch_size=32,\n    class_mode=\"categorical\",\n    color_mode='rgb',\n    subset=\"training\"\n)\n\nval_generator = datagen.flow_from_dataframe(\n    dataframe=labels_df,\n    directory=train_dir,\n    x_col=\"filename\",\n    y_col=\"city\", \n    target_size=(64, 64),\n    batch_size=32,\n    class_mode=\"categorical\",\n    color_mode='rgb',\n    subset=\"validation\"\n)\n\nmodel = Sequential([\n    Conv2D(64, (3, 3), padding='same', input_shape=(64, 64, 3), kernel_regularizer=l2(0.01)),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n\n    Conv2D(128, (3, 3), padding='same', kernel_regularizer=l2(0.01)),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n\n    Conv2D(256, (3, 3), padding='same', kernel_regularizer=l2(0.01)),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(pool_size=(2, 2)),\n\n    Flatten(),\n    Dense(512, kernel_regularizer=l2(0.01)),\n    BatchNormalization(),\n    Activation('relu'),\n    Dropout(0.5),\n\n    Dense(len(train_generator.class_indices), activation='softmax')\n])\n\nmodel.compile(\n    loss='categorical_crossentropy',\n    optimizer=Adam(learning_rate=0.001),\n    metrics=['accuracy']\n)\n\ncallbacks = [\n    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n]\n\n\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=50,\n    callbacks=callbacks\n)\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=pd.DataFrame({'filename': os.listdir(test_dir)}), \n    directory=test_dir,\n    x_col=\"filename\",\n    class_mode=None,  \n    target_size=(64, 64),\n    batch_size=1,\n    shuffle=False,\n    color_mode='rgb'\n)\n\npredictions = model.predict(test_generator)\npredicted_classes = np.argmax(predictions, axis=-1)\n\n\nclass_labels = list(train_generator.class_indices.keys())\npredicted_labels = [class_labels[idx] for idx in predicted_classes]\n\n\noutput = pd.DataFrame({\n    \"filename\": test_generator.filenames,\n    \"predicted_city\": predicted_labels\n})\noutput.to_csv(\"submission.csv\", index=False)\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T20:46:34.250251Z","iopub.execute_input":"2024-12-14T20:46:34.250817Z","iopub.status.idle":"2024-12-14T22:18:03.479061Z","shell.execute_reply.started":"2024-12-14T20:46:34.250770Z","shell.execute_reply":"2024-12-14T22:18:03.477672Z"}},"outputs":[{"name":"stdout","text":"Found 5600 validated image filenames belonging to 3 classes.\nFound 1400 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 762ms/step - accuracy: 0.5212 - loss: 9.8989 - val_accuracy: 0.3150 - val_loss: 3.2938 - learning_rate: 0.0010\nEpoch 2/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 703ms/step - accuracy: 0.6187 - loss: 2.1723 - val_accuracy: 0.3150 - val_loss: 2.1167 - learning_rate: 0.0010\nEpoch 3/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 702ms/step - accuracy: 0.6212 - loss: 1.5872 - val_accuracy: 0.4879 - val_loss: 1.5486 - learning_rate: 0.0010\nEpoch 4/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 713ms/step - accuracy: 0.6369 - loss: 1.4079 - val_accuracy: 0.4879 - val_loss: 1.5128 - learning_rate: 0.0010\nEpoch 5/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 705ms/step - accuracy: 0.6534 - loss: 1.3249 - val_accuracy: 0.5907 - val_loss: 1.5073 - learning_rate: 0.0010\nEpoch 6/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 704ms/step - accuracy: 0.6512 - loss: 1.3691 - val_accuracy: 0.5307 - val_loss: 1.4819 - learning_rate: 0.0010\nEpoch 7/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m129s\u001b[0m 729ms/step - accuracy: 0.6571 - loss: 1.3148 - val_accuracy: 0.5107 - val_loss: 1.5291 - learning_rate: 0.0010\nEpoch 8/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 708ms/step - accuracy: 0.6530 - loss: 1.3083 - val_accuracy: 0.5543 - val_loss: 1.5269 - learning_rate: 0.0010\nEpoch 9/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 707ms/step - accuracy: 0.6514 - loss: 1.3550 - val_accuracy: 0.4507 - val_loss: 2.6568 - learning_rate: 0.0010\nEpoch 10/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 706ms/step - accuracy: 0.6618 - loss: 1.1967 - val_accuracy: 0.6250 - val_loss: 1.2226 - learning_rate: 5.0000e-04\nEpoch 11/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 710ms/step - accuracy: 0.6801 - loss: 1.1096 - val_accuracy: 0.6993 - val_loss: 1.1237 - learning_rate: 5.0000e-04\nEpoch 12/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 703ms/step - accuracy: 0.6967 - loss: 1.1203 - val_accuracy: 0.5121 - val_loss: 1.5678 - learning_rate: 5.0000e-04\nEpoch 13/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 696ms/step - accuracy: 0.6948 - loss: 1.1309 - val_accuracy: 0.5107 - val_loss: 1.5542 - learning_rate: 5.0000e-04\nEpoch 14/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 705ms/step - accuracy: 0.7070 - loss: 1.1139 - val_accuracy: 0.5093 - val_loss: 1.6357 - learning_rate: 5.0000e-04\nEpoch 15/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 697ms/step - accuracy: 0.7305 - loss: 1.0114 - val_accuracy: 0.7043 - val_loss: 1.0192 - learning_rate: 2.5000e-04\nEpoch 16/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 700ms/step - accuracy: 0.7440 - loss: 0.9456 - val_accuracy: 0.6264 - val_loss: 1.1714 - learning_rate: 2.5000e-04\nEpoch 17/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 698ms/step - accuracy: 0.7599 - loss: 0.9359 - val_accuracy: 0.7307 - val_loss: 1.0140 - learning_rate: 2.5000e-04\nEpoch 18/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 701ms/step - accuracy: 0.7544 - loss: 0.9425 - val_accuracy: 0.6793 - val_loss: 1.1078 - learning_rate: 2.5000e-04\nEpoch 19/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 700ms/step - accuracy: 0.7504 - loss: 0.9519 - val_accuracy: 0.5200 - val_loss: 1.4603 - learning_rate: 2.5000e-04\nEpoch 20/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 698ms/step - accuracy: 0.7989 - loss: 0.8882 - val_accuracy: 0.6514 - val_loss: 1.3784 - learning_rate: 2.5000e-04\nEpoch 21/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 703ms/step - accuracy: 0.8180 - loss: 0.8138 - val_accuracy: 0.7107 - val_loss: 0.9509 - learning_rate: 1.2500e-04\nEpoch 22/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 695ms/step - accuracy: 0.8468 - loss: 0.6959 - val_accuracy: 0.6129 - val_loss: 1.3271 - learning_rate: 1.2500e-04\nEpoch 23/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 707ms/step - accuracy: 0.8591 - loss: 0.6776 - val_accuracy: 0.7693 - val_loss: 0.9519 - learning_rate: 1.2500e-04\nEpoch 24/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 699ms/step - accuracy: 0.8705 - loss: 0.6744 - val_accuracy: 0.7793 - val_loss: 0.9163 - learning_rate: 1.2500e-04\nEpoch 25/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 697ms/step - accuracy: 0.9004 - loss: 0.6262 - val_accuracy: 0.6836 - val_loss: 1.3613 - learning_rate: 1.2500e-04\nEpoch 26/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 691ms/step - accuracy: 0.9160 - loss: 0.6051 - val_accuracy: 0.7729 - val_loss: 0.9752 - learning_rate: 1.2500e-04\nEpoch 27/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 700ms/step - accuracy: 0.9249 - loss: 0.5645 - val_accuracy: 0.7714 - val_loss: 0.9833 - learning_rate: 1.2500e-04\nEpoch 28/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 695ms/step - accuracy: 0.9511 - loss: 0.5085 - val_accuracy: 0.7871 - val_loss: 0.8809 - learning_rate: 6.2500e-05\nEpoch 29/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 695ms/step - accuracy: 0.9896 - loss: 0.3542 - val_accuracy: 0.7250 - val_loss: 0.9710 - learning_rate: 6.2500e-05\nEpoch 30/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 698ms/step - accuracy: 0.9879 - loss: 0.2993 - val_accuracy: 0.7429 - val_loss: 0.9684 - learning_rate: 6.2500e-05\nEpoch 31/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 705ms/step - accuracy: 0.9861 - loss: 0.2791 - val_accuracy: 0.7857 - val_loss: 0.8315 - learning_rate: 6.2500e-05\nEpoch 32/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 693ms/step - accuracy: 0.9897 - loss: 0.2697 - val_accuracy: 0.7036 - val_loss: 1.2382 - learning_rate: 6.2500e-05\nEpoch 33/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 694ms/step - accuracy: 0.9802 - loss: 0.2904 - val_accuracy: 0.7093 - val_loss: 1.1635 - learning_rate: 6.2500e-05\nEpoch 34/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 693ms/step - accuracy: 0.9917 - loss: 0.2707 - val_accuracy: 0.6686 - val_loss: 1.3942 - learning_rate: 6.2500e-05\nEpoch 35/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 701ms/step - accuracy: 0.9928 - loss: 0.2465 - val_accuracy: 0.8043 - val_loss: 0.7559 - learning_rate: 3.1250e-05\nEpoch 36/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 701ms/step - accuracy: 0.9994 - loss: 0.2037 - val_accuracy: 0.7979 - val_loss: 0.8216 - learning_rate: 3.1250e-05\nEpoch 37/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 702ms/step - accuracy: 0.9968 - loss: 0.1927 - val_accuracy: 0.7893 - val_loss: 0.8656 - learning_rate: 3.1250e-05\nEpoch 38/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 703ms/step - accuracy: 0.9990 - loss: 0.1662 - val_accuracy: 0.8207 - val_loss: 0.7362 - learning_rate: 3.1250e-05\nEpoch 39/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 700ms/step - accuracy: 0.9972 - loss: 0.1589 - val_accuracy: 0.7693 - val_loss: 1.0236 - learning_rate: 3.1250e-05\nEpoch 40/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 701ms/step - accuracy: 0.9982 - loss: 0.1593 - val_accuracy: 0.7700 - val_loss: 0.9669 - learning_rate: 3.1250e-05\nEpoch 41/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 698ms/step - accuracy: 0.9989 - loss: 0.1447 - val_accuracy: 0.7836 - val_loss: 0.7714 - learning_rate: 3.1250e-05\nEpoch 42/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 704ms/step - accuracy: 0.9997 - loss: 0.1438 - val_accuracy: 0.8057 - val_loss: 0.7784 - learning_rate: 1.5625e-05\nEpoch 43/50\n\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 696ms/step - accuracy: 0.9998 - loss: 0.1290 - val_accuracy: 0.8121 - val_loss: 0.7461 - learning_rate: 1.5625e-05\nFound 2000 validated image filenames.\n\u001b[1m2000/2000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 11ms/step\n","output_type":"stream"}],"execution_count":1}]}